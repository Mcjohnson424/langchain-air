---
sidebar_position: 3
sidebar_label: Integrations
---

import CodeBlock from "@theme/CodeBlock";

# Integrations: Chat Models

LangChain offers a number of Chat Models implementations that integrate with various model providers. These are:

## `ChatOpenAI`

import OpenAI from "@examples/models/chat/integration_openai.ts";

<CodeBlock language="typescript">{OpenAI}</CodeBlock>

## Azure `ChatOpenAI`

import AzureOpenAI from "@examples/models/chat/integration_azure_openai.ts";

<CodeBlock language="typescript">{AzureOpenAI}</CodeBlock>

## `ChatAnthropic`

import Anthropic from "@examples/models/chat/integration_anthropic.ts";

<CodeBlock language="typescript">{Anthropic}</CodeBlock>

## `PromptLayerChatOpenAI`

You can pass in the optional `returnPromptLayerId` boolean to get a `promptLayerRequestId` like below. Here is an example of getting the PromptLayerChatOpenAI requestID:

```typescript
import { PromptLayerChatOpenAI } from "langchain/chat_models/openai";

const chat = new PromptLayerChatOpenAI({
  returnPromptLayerId: true,
});

const respA = await chat.generate([
  [
    new SystemChatMessage(
      "You are a helpful assistant that translates English to French."
    ),
  ],
]);

console.log(JSON.stringify(respA, null, 3));

/*
  {
    "generations": [
      [
        {
          "text": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?",
          "message": {
            "type": "ai",
            "data": {
              "content": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?"
            }
          },
          "generationInfo": {
            "promptLayerRequestId": 2300682
          }
        }
      ]
    ],
    "llmOutput": {
      "tokenUsage": {
        "completionTokens": 35,
        "promptTokens": 19,
        "totalTokens": 54
      }
    }
  }
*/
```

## `Google Vertex AI`

The Vertex AI implementation is meant to be used in Node.js and not
directly from a browser, since it requires a service account to use.

Before running this code, you should make sure the Vertex AI API is
enabled for the relevant project and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.

```bash npm2yarn
npm install google-auth-library
```

The ChatGoogleVertexAI class works just like other chat-based LLMs,
with a few exceptions:

1. The first `SystemChatMessage` passed in is mapped to the "context" parameter that the PaLM model expects.
   No other `SystemChatMessages` are allowed.
2. After the first `SystemChatMessage`, there must be an odd number of messages, representing a conversation between a human and the model.
3. Human messages must alternate with AI messages.

import ChatGoogleVertexAI from "@examples/models/chat/integration_googlevertexai.ts";

<CodeBlock language="typescript">{ChatGoogleVertexAI}</CodeBlock>

There is also an optional `examples` constructor parameter that can help the model understand what an appropriate response
looks like.

import ChatGoogleVertexAIExamples from "@examples/models/chat/integration_googlevertexai-examples.ts";

<CodeBlock language="typescript">{ChatGoogleVertexAIExamples}</CodeBlock>
